{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T10:19:30.976949Z",
     "start_time": "2019-02-01T10:19:30.970172Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T10:09:10.855133Z",
     "start_time": "2019-02-01T10:09:10.846711Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Submission function\n",
    "def make_submission(ytest, filename=\"Titanic Prediction.csv\"):\n",
    "    submission = pd.DataFrame({'PassengerId':xtest_fe['PassengerId'],'Survived':ytest})\n",
    "    submission.to_csv(filename,index=False)\n",
    "    print('Saved file: ' + filename)\n",
    "    \n",
    "submissions = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T10:28:35.861715Z",
     "start_time": "2019-02-01T10:28:35.831209Z"
    }
   },
   "outputs": [],
   "source": [
    "xtest_fe = pd.read_csv('xtest_fe')\n",
    "xtrain_fe = pd.read_csv('xtrain_fe')\n",
    "labels = pd.read_csv('train.csv')[\"Survived\"]\n",
    "labels = labels.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T10:28:37.522133Z",
     "start_time": "2019-02-01T10:28:37.516361Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 68)\n",
      "(891,)\n"
     ]
    }
   ],
   "source": [
    "print(xtrain_fe.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "\n",
    "- 500 estimators RFClassifier : **0.73205**\n",
    "- Optimized RandomSearch hyperparameters : **0.77033**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T10:20:01.458100Z",
     "start_time": "2019-02-01T10:19:59.936575Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved file: Titanic Predictions RF500 - FE.csv\n"
     ]
    }
   ],
   "source": [
    "# Filtering string columns for random forest\n",
    "\n",
    "# Create Classifier\n",
    "rf = RandomForestClassifier(n_estimators=1000)\n",
    "\n",
    "# Fit and predict\n",
    "rf.fit(xtrain_fe, np.ravel(labels))\n",
    "ytest_rf = rf.predict(xtest_fe)\n",
    "\n",
    "# Make Submission\n",
    "make_submission(ytest_rf, \"Titanic Predictions RF500 - FE.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T08:10:14.638657Z",
     "start_time": "2019-02-01T08:10:14.634392Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submissions[\"Random Forest Quick\"] = 0.73205\n",
    "submissions[\"Random Forest Feat. Eng.\"] = 0.74641"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomizedSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T08:25:25.363870Z",
     "start_time": "2019-02-01T08:11:37.112500Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 300 candidates, totalling 1500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    9.7s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   13.8s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   15.2s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   16.6s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   20.9s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:   23.3s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   25.2s\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:   31.3s\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:   37.1s\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed:   43.0s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:   53.6s\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 213 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 234 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 257 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 305 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 330 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 384 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 413 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 473 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=-1)]: Done 504 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=-1)]: Done 537 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=-1)]: Done 570 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=-1)]: Done 605 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=-1)]: Done 677 tasks      | elapsed:  6.5min\n",
      "[Parallel(n_jobs=-1)]: Done 714 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=-1)]: Done 753 tasks      | elapsed:  7.2min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  7.5min\n",
      "[Parallel(n_jobs=-1)]: Done 833 tasks      | elapsed:  7.9min\n",
      "[Parallel(n_jobs=-1)]: Done 874 tasks      | elapsed:  8.2min\n",
      "[Parallel(n_jobs=-1)]: Done 917 tasks      | elapsed:  8.5min\n",
      "[Parallel(n_jobs=-1)]: Done 960 tasks      | elapsed:  8.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1005 tasks      | elapsed:  9.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1050 tasks      | elapsed:  9.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1097 tasks      | elapsed: 10.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1144 tasks      | elapsed: 10.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1193 tasks      | elapsed: 11.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed: 11.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1293 tasks      | elapsed: 11.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1344 tasks      | elapsed: 12.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1397 tasks      | elapsed: 12.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1450 tasks      | elapsed: 13.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1500 out of 1500 | elapsed: 13.8min finished\n"
     ]
    }
   ],
   "source": [
    "# Classifier\n",
    "rf2 = RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "# Create hyperparameter options\n",
    "rf_max_depth=[2, 3, 5, 7, 10, 20, 35, 60, 100]\n",
    "rf_n_estimators=[100, 200, 500, 1000, 1200]\n",
    "rf_min_samples_split=[2, 4, 6, 10]\n",
    "rf_criterion=['gini', 'entropy']\n",
    "\n",
    "hyperparameters = dict(\n",
    "    max_depth=rf_max_depth,\n",
    "    min_samples_split=rf_min_samples_split,\n",
    "    n_estimators=rf_n_estimators,\n",
    "    criterion=rf_criterion)\n",
    "\n",
    "# Create randomized grid search\n",
    "clf = RandomizedSearchCV(rf2, hyperparameters, random_state=1, n_iter=300, cv=5, verbose=10, n_jobs=-1)\n",
    "\n",
    "# Fit randomized search\n",
    "best_model = clf.fit(xtrain_fe, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T08:29:22.824120Z",
     "start_time": "2019-02-01T08:29:22.811796Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=7, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T08:30:16.601325Z",
     "start_time": "2019-02-01T08:30:16.211768Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved file: Titanic Predictions RF-RandomSearch.csv\n"
     ]
    }
   ],
   "source": [
    "# Create Classifier\n",
    "rf = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=7, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
    "            oob_score=False, random_state=None, verbose=0,\n",
    "            warm_start=False)\n",
    "\n",
    "# Fit and predict\n",
    "rf.fit(xtrain_fe, labels)\n",
    "ytest_rf = rf.predict(xtest_fe)\n",
    "\n",
    "# Make Submission\n",
    "make_submission(ytest_rf, \"Titanic Predictions RF-RandomSearch.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T10:33:05.988037Z",
     "start_time": "2019-02-01T10:32:59.378092Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8081392317930398"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(rf, xtrain_fe, labels, cv=5)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submissions[\"Random Forest tuned\"] = 0.78947"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T09:04:10.630181Z",
     "start_time": "2019-02-01T08:55:32.204820Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    9.9s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   49.1s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done 213 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=-1)]: Done 234 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=-1)]: Done 257 tasks      | elapsed:  7.6min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  8.0min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  8.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[10:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "Best max_depth: 3\n",
      "Best learning_rate: 0.01\n",
      "Best n_estimators: 200\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Classifier\n",
    "xgb = XGBClassifier(n_jobs=-1, silent=False)\n",
    "\n",
    "# Create hyperparameter options\n",
    "xgb_max_depth=[3, 5, 10, 20, 50]             # Usual values between 3-10\n",
    "xgb_learning_rate=[0.01, 0.1, 0.5, 1, 2]    # Makes the model more robust by shrinking the weights on each step\n",
    "xgb_n_estimators=[100, 200, 500, 1000, 1200]\n",
    "xgb_booster=['gbtree', 'gblinear', 'dart']\n",
    "xgb_reg_lambda=[1, 2]                       # L2 used to reduce overfitting\n",
    "\n",
    "hyperparameters = dict(\n",
    "    max_depth = xgb_max_depth, \n",
    "    learning_rate = xgb_learning_rate,\n",
    "    n_estimators = xgb_n_estimators,\n",
    "    booster=xgb_booster,\n",
    "    reg_lambda=xgb_reg_lambda)\n",
    "\n",
    "# Create randomized grid search\n",
    "rscv = RandomizedSearchCV(xgb, hyperparameters, random_state=1, n_iter=100, cv=3, verbose=10, n_jobs=-1)\n",
    "# Fit randomized search\n",
    "best_model = rscv.fit(xtrain_fe, labels)\n",
    "\n",
    "# View Hyperparameter Values Of Best Model\n",
    "print('Best max_depth:', best_model.best_estimator_.get_params()['max_depth'])\n",
    "print('Best learning_rate:', best_model.best_estimator_.get_params()['learning_rate'])\n",
    "print('Best n_estimators:', best_model.best_estimator_.get_params()['n_estimators'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T09:24:51.211913Z",
     "start_time": "2019-02-01T09:24:40.662017Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved file: Titanic Predictions XGB.csv\n"
     ]
    }
   ],
   "source": [
    "xgbc = XGBClassifier(\n",
    "    n_jobs=-1, \n",
    "    max_depth=10, \n",
    "    learning_rate=0.001, \n",
    "    n_estimators=3000)\n",
    "\n",
    "xgbc.fit(xtrain_fe, labels)\n",
    "\n",
    "ytest_xgb = xgbc.predict(xtest_fe)\n",
    "\n",
    "make_submission(ytest_xgb, \"Titanic Predictions XGB.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T09:50:07.606518Z",
     "start_time": "2019-02-01T09:50:07.602103Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submissions[\"XGBoost depth=3 LR=0.001 n_est=3K\"] = 0.78947 \n",
    "submissions[\"XGBoost depth=10 LR=0.001 n_est=3K\"] = 0.75119"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T09:37:33.085223Z",
     "start_time": "2019-02-01T09:37:26.195197Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved file: Titanic Predictions LGB.csv\n"
     ]
    }
   ],
   "source": [
    "lgb_estimator = lgb.LGBMClassifier(\n",
    "    boosting_type='gbdt',  \n",
    "    objective='binary', \n",
    "    n_estimators=10000, \n",
    "    learning_rate=0.001, \n",
    "    metric='binary_logloss',\n",
    "    n_jobs=-1)\n",
    "\n",
    "lgb_estimator.fit(xtrain_fe, labels)\n",
    "ytest_lgb = lgb_estimator.predict(xtest_fe)\n",
    "\n",
    "make_submission(ytest_lgb, \"Titanic Predictions LGB.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T09:45:18.020558Z",
     "start_time": "2019-02-01T09:45:18.016516Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submissions[\"LGBM raw\"] = 0.77033"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T09:44:35.404404Z",
     "start_time": "2019-02-01T09:41:53.760257Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Alex/Programmes/Anaconda/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:271: UserWarning: The total space of parameters 360 is smaller than n_iter=500. Running 360 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 360 candidates, totalling 1080 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed:    9.7s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:   12.8s\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed:   19.0s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   25.8s\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed:   40.0s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   44.0s\n",
      "[Parallel(n_jobs=-1)]: Done 213 tasks      | elapsed:   45.3s\n",
      "[Parallel(n_jobs=-1)]: Done 234 tasks      | elapsed:   46.4s\n",
      "[Parallel(n_jobs=-1)]: Done 257 tasks      | elapsed:   48.9s\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:   52.4s\n",
      "[Parallel(n_jobs=-1)]: Done 305 tasks      | elapsed:   59.7s\n",
      "[Parallel(n_jobs=-1)]: Done 330 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 384 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 413 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 473 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 504 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 537 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 570 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 605 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 677 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 714 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 753 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 833 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 874 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 917 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 960 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1005 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1050 tasks      | elapsed:  2.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best num_leaves: 31\n",
      "Best reg_alpha: 0.1\n",
      "Best lambda_l1: 1.5\n",
      "Best lambda_l2: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1080 out of 1080 | elapsed:  2.7min finished\n"
     ]
    }
   ],
   "source": [
    "# Classifier\n",
    "lgb_estimator = lgb.LGBMClassifier(\n",
    "    boosting_type='gbdt',  \n",
    "    objective='binary', \n",
    "    n_estimators=100, \n",
    "    learning_rate=0.1, \n",
    "    metric='binary_logloss',\n",
    "    n_jobs=-1)\n",
    "\n",
    "# Create hyperparameter options\n",
    "hyperparameters = dict(\n",
    "    num_leaves = [31, 60, 128, 160, 250], \n",
    "    reg_alpha = [0.1, 0.5],\n",
    "    n_estimators = [100, 200, 500, 1000, 2000, 5000],\n",
    "    lambda_l1 = [0, 1, 1.5],\n",
    "    lambda_l2 = [0, 1],\n",
    "    max_depth = [7])\n",
    "\n",
    "# Create randomized grid search\n",
    "rscv = RandomizedSearchCV(\n",
    "    lgb_estimator, hyperparameters,\n",
    "    n_iter=500, cv=3, \n",
    "    verbose=10, n_jobs=-1)\n",
    "\n",
    "# Fit randomized search\n",
    "best_model = rscv.fit(xtrain_fe, labels)\n",
    "\n",
    "# View Hyperparameter Values Of Best Model\n",
    "print('Best num_leaves:', best_model.best_estimator_.get_params()['num_leaves'])\n",
    "print('Best reg_alpha:', best_model.best_estimator_.get_params()['reg_alpha'])\n",
    "print('Best lambda_l1:', best_model.best_estimator_.get_params()['lambda_l1'])\n",
    "print('Best lambda_l2:', best_model.best_estimator_.get_params()['lambda_l2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T09:47:25.898120Z",
     "start_time": "2019-02-01T09:47:20.594419Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved file: Titanic Predictions LGB tuned.csv\n"
     ]
    }
   ],
   "source": [
    "lgb_estimator = lgb.LGBMClassifier(\n",
    "    boosting_type='gbdt',  \n",
    "    objective='binary', \n",
    "    n_estimators=10000, \n",
    "    learning_rate=0.001, \n",
    "    num_leaves = 31,\n",
    "    metric='binary_logloss',\n",
    "    reg_alpha = 0.1,\n",
    "    lambda_l1 = 1.5,\n",
    "    lambda_l2 = 1,\n",
    "    n_jobs=-1)\n",
    "\n",
    "lgb_estimator.fit(xtrain_fe, labels)\n",
    "ytest_lgb = lgb_estimator.predict(xtest_fe)\n",
    "\n",
    "make_submission(ytest_lgb, \"Titanic Predictions LGB tuned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T09:48:26.151969Z",
     "start_time": "2019-02-01T09:48:26.147526Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submissions[\"LGBM tuned\"] = 0.76555"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T09:50:11.033153Z",
     "start_time": "2019-02-01T09:50:11.026328Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LGBM raw': 0.77033,\n",
       " 'LGBM tuned': 0.76555,\n",
       " 'Random Forest Feat. Eng.': 0.74641,\n",
       " 'Random Forest Quick': 0.73205,\n",
       " 'XGBoost depth=10 LR=0.001 n_est=3K': 0.75119,\n",
       " 'XGBoost depth=3 LR=0.001 n_est=3K': 0.78947}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submissions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLA Ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T10:30:39.860712Z",
     "start_time": "2019-02-01T10:30:38.899074Z"
    }
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-119-a3d9cabec1a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mMLA_compare\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'MLA Time'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0mMLA_compare\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'MLA Train Accuracy Mean'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m     \u001b[0mMLA_compare\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'MLA Test Accuracy Mean'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;31m#if this is a non-bias random sample, then +/-3 standard deviations (std) from the mean, should statistically capture 99.7% of the subsets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble, gaussian_process, linear_model\n",
    "from sklearn import naive_bayes, neighbors, svm, tree, discriminant_analysis\n",
    "from sklearn import model_selection\n",
    "\n",
    "\n",
    "#Machine Learning Algorithm (MLA) Selection and Initialization\n",
    "MLA = [\n",
    "    #Ensemble Methods\n",
    "    ensemble.AdaBoostClassifier(),\n",
    "    ensemble.BaggingClassifier(),\n",
    "    ensemble.ExtraTreesClassifier(),\n",
    "    ensemble.GradientBoostingClassifier(),\n",
    "    ensemble.RandomForestClassifier(),\n",
    "\n",
    "    #Gaussian Processes\n",
    "    gaussian_process.GaussianProcessClassifier(),\n",
    "    \n",
    "    #GLM\n",
    "    linear_model.LogisticRegressionCV(),\n",
    "    linear_model.PassiveAggressiveClassifier(),\n",
    "    linear_model.RidgeClassifierCV(),\n",
    "    linear_model.SGDClassifier(),\n",
    "    linear_model.Perceptron(),\n",
    "    \n",
    "    #Navies Bayes\n",
    "    naive_bayes.BernoulliNB(),\n",
    "    naive_bayes.GaussianNB(),\n",
    "    \n",
    "    #Nearest Neighbor\n",
    "    neighbors.KNeighborsClassifier(),\n",
    "    \n",
    "    #SVM\n",
    "    svm.SVC(probability=True),\n",
    "    svm.NuSVC(probability=True),\n",
    "    svm.LinearSVC(),\n",
    "    \n",
    "    #Trees    \n",
    "    tree.DecisionTreeClassifier(),\n",
    "    tree.ExtraTreeClassifier(),\n",
    "    \n",
    "    #Discriminant Analysis\n",
    "    discriminant_analysis.LinearDiscriminantAnalysis(),\n",
    "    discriminant_analysis.QuadraticDiscriminantAnalysis(),\n",
    "\n",
    "    \n",
    "    #xgboost\n",
    "    XGBClassifier()    \n",
    "    ]\n",
    "\n",
    "\n",
    "\n",
    "#split dataset in cross-validation with this splitter class: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html#sklearn.model_selection.ShuffleSplit\n",
    "#note: this is an alternative to train_test_split\n",
    "cv_split = model_selection.ShuffleSplit(n_splits = 10, test_size = .3, train_size = .6, random_state = 0 ) # run model 10x with 60/30 split intentionally leaving out 10%\n",
    "\n",
    "#create table to compare MLA metrics\n",
    "MLA_columns = ['MLA Name', 'MLA Parameters','MLA Train Accuracy Mean', 'MLA Test Accuracy Mean', 'MLA Test Accuracy 3*STD' ,'MLA Time']\n",
    "MLA_compare = pd.DataFrame(columns = MLA_columns)\n",
    "\n",
    "#create table to compare MLA predictions\n",
    "MLA_predict = labels\n",
    "\n",
    "#index through MLA and save performance to table\n",
    "row_index = 0\n",
    "for alg in MLA:\n",
    "\n",
    "    #set name and parameters\n",
    "    MLA_name = alg.__class__.__name__\n",
    "    MLA_compare.loc[row_index, 'MLA Name'] = MLA_name\n",
    "    MLA_compare.loc[row_index, 'MLA Parameters'] = str(alg.get_params())\n",
    "    \n",
    "    #score model with cross validation:\n",
    "    cv_results = model_selection.cross_val_score(alg, xtrain_fe[0:891], np.ravel(labels)[0:891], cv  = cv_split)\n",
    "    \n",
    "    MLA_compare.loc[row_index, 'MLA Time'] = cv_results.mean()\n",
    "    MLA_compare.loc[row_index, 'MLA Train Accuracy Mean'] = cv_results['train_score'].mean()\n",
    "    MLA_compare.loc[row_index, 'MLA Test Accuracy Mean'] = cv_results['test_score'].mean()   \n",
    "    #if this is a non-bias random sample, then +/-3 standard deviations (std) from the mean, should statistically capture 99.7% of the subsets\n",
    "    MLA_compare.loc[row_index, 'MLA Test Accuracy 3*STD'] = cv_results['test_score'].std()*3   #let's know the worst that can happen!\n",
    "    \n",
    "\n",
    "    #save MLA predictions - see section 6 for usage\n",
    "    alg.fit(xtrain_fe, labels)\n",
    "    MLA_predict[MLA_name] = alg.predict(xtest_fe)\n",
    "    \n",
    "    row_index+=1\n",
    "\n",
    "    \n",
    "#print and sort table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sort_values.html\n",
    "MLA_compare.sort_values(by = ['MLA Test Accuracy Mean'], ascending = False, inplace = True)\n",
    "MLA_compare\n",
    "#MLA_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
